{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "environment = `rag_env`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we have ChatGPT, why don't we use it directly to summarise documents or processing them instead of creating an app?\n",
    "\n",
    "1. It will involve too many copy and paste for contents from documents.\n",
    "2. Copy and Paste on ChatGPT will not create an *aggregate knowledge base* which I may want to use for a long time.\n",
    "3. ChatGPT has limit on amount of words that can be processed by it. So, what if your content is larger in size than the token limit?\n",
    "4. If we have an app, We can smartly send the pertinent text *chunk* to LLM to get the answer to our question - therby, saving cost. \n",
    "\n",
    "Sidenote: To stop hallucination by LLM  - In your prompts add these words - **Who is Modi? Do not make things up!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Technical Architecture**\n",
    "\n",
    "<span style = \"color: yellow\"> Image to add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain has many types of `document_loaders` - helps in loading text i.e. converting words from a document into a machine readable format.\n",
    "\n",
    "For e.g: \n",
    "- `TextLoader` - to read from *.txt* files\n",
    "- `CSVLoader` - to read from *.csv* files\n",
    "- `PyPDFLoader` - to read from *.pdf* files. There are many different modules in `langchain` to load pdfs. It will be a good idea to explore them later to see what works best for you.\n",
    "- `UnstructuredURLLoader` - to read from *url* links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color: red\"> Loading table from csvloader vs from pdfloader is same or different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading *.txt* file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader, CSVLoader, PyPDFLoader, UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'nvda_news_1.txt'}, page_content=\"The stock of NVIDIA Corp (NASDAQ:NVDA) experienced a daily loss of -3.56% and a 3-month gain of 32.35%. With an Earnings Per Share (EPS) (EPS) of $1.92, the question arises: is the stock significantly overvalued? This article aims to provide a detailed valuation analysis of NVIDIA, offering insights into its financial strength, profitability, growth, and more. We invite you to delve into this comprehensive analysis.\\n\\nCompany Overview\\nWarning! GuruFocus has detected 10 Warning Signs with NVDA. Click here to check it out.\\n\\nNVDA 30-Year Financial Data\\n\\nThe intrinsic value of NVDA\\n\\n\\nNVIDIA Corp (NASDAQ:NVDA) is a leading designer of discrete graphics processing units that enhance the experience on computing platforms. The firm's chips are widely used in various end markets, including PC gaming and data centers. In recent years, NVIDIA has broadened its focus from traditional PC graphics applications such as gaming to more complex and favorable opportunities, including artificial intelligence and autonomous driving, leveraging the high-performance capabilities of its products.\\n\\nCurrently, NVIDIA's stock price stands at $418.01, significantly higher than the GF Value of $310.28, indicating the stock might be overvalued. With a market cap of $1 trillion, the valuation seems steep. The following analysis aims to delve deeper into the company's value.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nUnderstanding the GF Value\\nThe GF Value is a unique measure of the intrinsic value of a stock, calculated based on historical trading multiples, a GuruFocus adjustment factor, and future business performance estimates. If the stock price is significantly above the GF Value Line, it is overvalued, and its future return is likely to be poor. Conversely, if it is significantly below the GF Value Line, its future return will likely be higher.\\n\\nAccording to GuruFocus Value calculation, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. The stock's current price of $418.01 per share and the market cap of $1 trillion further strengthen this assumption.\\n\\nGiven that NVIDIA is significantly overvalued, the long-term return of its stock is likely to be much lower than its future business growth.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nLink: These companies may deliver higher future returns at reduced risk.\\n\\nFinancial Strength of NVIDIA\\nExamining the financial strength of a company is crucial before investing in its stock. Companies with poor financial strength pose a higher risk of permanent loss. NVIDIA's cash-to-debt ratio of 1.27 is worse than 58.04% of companies in the Semiconductors industry. However, NVIDIA's overall financial strength is 8 out of 10, indicating a strong financial position.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nProfitability and Growth\\nConsistent profitability over the long term reduces the risk for investors. NVIDIA, with its profitability ranking of 10 out of 10, has been profitable for the past 10 years. The company's operating margin of 17.37% ranks better than 76.5% of companies in the Semiconductors industry.\\n\\nHowever, growth is a crucial factor in a company's valuation. NVIDIA's growth ranks worse than 52.99% of companies in the Semiconductors industry, with its 3-year average revenue growth rate better than 87.88% of companies in the industry.\\n\\nROIC vs WACC\\nComparing a company's return on invested capital (ROIC) to its weighted average cost of capital (WACC) is an effective way to evaluate its profitability. Over the past 12 months, NVIDIA's ROIC was 20.32 while its WACC was 16.74, suggesting that the company is creating value for its shareholders.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nConclusion\\nIn conclusion, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. Despite its strong financial condition and profitability, its growth ranks lower than 52.99% of companies in the Semiconductors industry. To learn more about NVIDIA stock, you can check out its 30-Year Financials here.\\n\\nTo find out the high quality companies that may deliver above-average returns, please check out GuruFocus High Quality Low Capex Screener.\\n\\nThis article first appeared on GuruFocus.\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"nvda_news_1.txt\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.document_loaders.text.TextLoader"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " 'alazy_load',\n",
       " 'aload',\n",
       " 'autodetect_encoding',\n",
       " 'encoding',\n",
       " 'file_path',\n",
       " 'lazy_load',\n",
       " 'load',\n",
       " 'load_and_split']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nvda_news_1.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>industry</th>\n",
       "      <th>release_year</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>studio</th>\n",
       "      <th>language_id</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>unit</th>\n",
       "      <th>currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>K.G.F: Chapter 2</td>\n",
       "      <td>Bollywood</td>\n",
       "      <td>2022</td>\n",
       "      <td>8.4</td>\n",
       "      <td>Hombale Films</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>Billions</td>\n",
       "      <td>INR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Doctor Strange in the Multiverse of Madness</td>\n",
       "      <td>Hollywood</td>\n",
       "      <td>2022</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>954.8</td>\n",
       "      <td>Millions</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Thor: The Dark World</td>\n",
       "      <td>Hollywood</td>\n",
       "      <td>2013</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "      <td>644.8</td>\n",
       "      <td>Millions</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Thor: Ragnarok</td>\n",
       "      <td>Hollywood</td>\n",
       "      <td>2017</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>5</td>\n",
       "      <td>180</td>\n",
       "      <td>854</td>\n",
       "      <td>Millions</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Thor: Love and Thunder</td>\n",
       "      <td>Hollywood</td>\n",
       "      <td>2022</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Marvel Studios</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>670</td>\n",
       "      <td>Millions</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>Sholay</td>\n",
       "      <td>Bollywood</td>\n",
       "      <td>1975</td>\n",
       "      <td>8.1</td>\n",
       "      <td>United Producers</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>Dilwale Dulhania Le Jayenge</td>\n",
       "      <td>Bollywood</td>\n",
       "      <td>1995</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Yash Raj Films</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>2000</td>\n",
       "      <td>Millions</td>\n",
       "      <td>INR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108</td>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>Bollywood</td>\n",
       "      <td>2009</td>\n",
       "      <td>8.4</td>\n",
       "      <td>Vinod Chopra Films</td>\n",
       "      <td>1</td>\n",
       "      <td>550</td>\n",
       "      <td>4000</td>\n",
       "      <td>Millions</td>\n",
       "      <td>INR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>109</td>\n",
       "      <td>Kabhi Khushi Kabhie Gham</td>\n",
       "      <td>Bollywood</td>\n",
       "      <td>2001</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Dharma Productions</td>\n",
       "      <td>1</td>\n",
       "      <td>390</td>\n",
       "      <td>1360</td>\n",
       "      <td>Millions</td>\n",
       "      <td>INR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                        title   industry  \\\n",
       "0       101                             K.G.F: Chapter 2  Bollywood   \n",
       "1       102  Doctor Strange in the Multiverse of Madness  Hollywood   \n",
       "2       103                         Thor: The Dark World  Hollywood   \n",
       "3       104                               Thor: Ragnarok  Hollywood   \n",
       "4       105                       Thor: Love and Thunder  Hollywood   \n",
       "5       106                                       Sholay  Bollywood   \n",
       "6       107                  Dilwale Dulhania Le Jayenge  Bollywood   \n",
       "7       108                                     3 Idiots  Bollywood   \n",
       "8       109                     Kabhi Khushi Kabhie Gham  Bollywood   \n",
       "\n",
       "   release_year  imdb_rating              studio  language_id         budget  \\\n",
       "0          2022          8.4       Hombale Films            3              1   \n",
       "1          2022          7.0      Marvel Studios            5            200   \n",
       "2          2013          6.8      Marvel Studios            5            165   \n",
       "3          2017          7.9      Marvel Studios            5            180   \n",
       "4          2022          6.8      Marvel Studios            5            250   \n",
       "5          1975          8.1    United Producers            1  Not Available   \n",
       "6          1995          8.0      Yash Raj Films            1            400   \n",
       "7          2009          8.4  Vinod Chopra Films            1            550   \n",
       "8          2001          7.4  Dharma Productions            1            390   \n",
       "\n",
       "         revenue           unit       currency  \n",
       "0           12.5       Billions            INR  \n",
       "1          954.8       Millions            USD  \n",
       "2          644.8       Millions            USD  \n",
       "3            854       Millions            USD  \n",
       "4            670       Millions            USD  \n",
       "5  Not Available  Not Available  Not Available  \n",
       "6           2000       Millions            INR  \n",
       "7           4000       Millions            INR  \n",
       "8           1360       Millions            INR  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('movies.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'movies.csv', 'row': 0}, page_content='movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 1}, page_content='movie_id: 102\\ntitle: Doctor Strange in the Multiverse of Madness\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 7\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 200\\nrevenue: 954.8\\nunit: Millions\\ncurrency: USD'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 2}, page_content='movie_id: 103\\ntitle: Thor: The Dark World\\nindustry: Hollywood\\nrelease_year: 2013\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 165\\nrevenue: 644.8\\nunit: Millions\\ncurrency: USD'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 3}, page_content='movie_id: 104\\ntitle: Thor: Ragnarok\\nindustry: Hollywood\\nrelease_year: 2017\\nimdb_rating: 7.9\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 180\\nrevenue: 854\\nunit: Millions\\ncurrency: USD'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 4}, page_content='movie_id: 105\\ntitle: Thor: Love and Thunder\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 250\\nrevenue: 670\\nunit: Millions\\ncurrency: USD'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 5}, page_content='movie_id: 106\\ntitle: Sholay\\nindustry: Bollywood\\nrelease_year: 1975\\nimdb_rating: 8.1\\nstudio: United Producers\\nlanguage_id: 1\\nbudget: Not Available\\nrevenue: Not Available\\nunit: Not Available\\ncurrency: Not Available'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 6}, page_content='movie_id: 107\\ntitle: Dilwale Dulhania Le Jayenge\\nindustry: Bollywood\\nrelease_year: 1995\\nimdb_rating: 8\\nstudio: Yash Raj Films\\nlanguage_id: 1\\nbudget: 400\\nrevenue: 2000\\nunit: Millions\\ncurrency: INR'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 7}, page_content='movie_id: 108\\ntitle: 3 Idiots\\nindustry: Bollywood\\nrelease_year: 2009\\nimdb_rating: 8.4\\nstudio: Vinod Chopra Films\\nlanguage_id: 1\\nbudget: 550\\nrevenue: 4000\\nunit: Millions\\ncurrency: INR'),\n",
       " Document(metadata={'source': 'movies.csv', 'row': 8}, page_content='movie_id: 109\\ntitle: Kabhi Khushi Kabhie Gham\\nindustry: Bollywood\\nrelease_year: 2001\\nimdb_rating: 7.4\\nstudio: Dharma Productions\\nlanguage_id: 1\\nbudget: 390\\nrevenue: 1360\\nunit: Millions\\ncurrency: INR')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = CSVLoader(file_path=\"movies.csv\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'movies.csv', 'row': 0}, page_content='movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'movies.csv', 'row': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for every row the metadata is `movies.csv`. Maybe we want to change that. Maybe we want `title` as the metadat for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'K.G.F: Chapter 2', 'row': 0}, page_content='movie_id: 101\\ntitle: K.G.F: Chapter 2\\nindustry: Bollywood\\nrelease_year: 2022\\nimdb_rating: 8.4\\nstudio: Hombale Films\\nlanguage_id: 3\\nbudget: 1\\nrevenue: 12.5\\nunit: Billions\\ncurrency: INR'),\n",
       " Document(metadata={'source': 'Doctor Strange in the Multiverse of Madness', 'row': 1}, page_content='movie_id: 102\\ntitle: Doctor Strange in the Multiverse of Madness\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 7\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 200\\nrevenue: 954.8\\nunit: Millions\\ncurrency: USD'),\n",
       " Document(metadata={'source': 'Thor: The Dark World', 'row': 2}, page_content='movie_id: 103\\ntitle: Thor: The Dark World\\nindustry: Hollywood\\nrelease_year: 2013\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 165\\nrevenue: 644.8\\nunit: Millions\\ncurrency: USD'),\n",
       " Document(metadata={'source': 'Thor: Ragnarok', 'row': 3}, page_content='movie_id: 104\\ntitle: Thor: Ragnarok\\nindustry: Hollywood\\nrelease_year: 2017\\nimdb_rating: 7.9\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 180\\nrevenue: 854\\nunit: Millions\\ncurrency: USD'),\n",
       " Document(metadata={'source': 'Thor: Love and Thunder', 'row': 4}, page_content='movie_id: 105\\ntitle: Thor: Love and Thunder\\nindustry: Hollywood\\nrelease_year: 2022\\nimdb_rating: 6.8\\nstudio: Marvel Studios\\nlanguage_id: 5\\nbudget: 250\\nrevenue: 670\\nunit: Millions\\ncurrency: USD'),\n",
       " Document(metadata={'source': 'Sholay', 'row': 5}, page_content='movie_id: 106\\ntitle: Sholay\\nindustry: Bollywood\\nrelease_year: 1975\\nimdb_rating: 8.1\\nstudio: United Producers\\nlanguage_id: 1\\nbudget: Not Available\\nrevenue: Not Available\\nunit: Not Available\\ncurrency: Not Available'),\n",
       " Document(metadata={'source': 'Dilwale Dulhania Le Jayenge', 'row': 6}, page_content='movie_id: 107\\ntitle: Dilwale Dulhania Le Jayenge\\nindustry: Bollywood\\nrelease_year: 1995\\nimdb_rating: 8\\nstudio: Yash Raj Films\\nlanguage_id: 1\\nbudget: 400\\nrevenue: 2000\\nunit: Millions\\ncurrency: INR'),\n",
       " Document(metadata={'source': '3 Idiots', 'row': 7}, page_content='movie_id: 108\\ntitle: 3 Idiots\\nindustry: Bollywood\\nrelease_year: 2009\\nimdb_rating: 8.4\\nstudio: Vinod Chopra Films\\nlanguage_id: 1\\nbudget: 550\\nrevenue: 4000\\nunit: Millions\\ncurrency: INR'),\n",
       " Document(metadata={'source': 'Kabhi Khushi Kabhie Gham', 'row': 8}, page_content='movie_id: 109\\ntitle: Kabhi Khushi Kabhie Gham\\nindustry: Bollywood\\nrelease_year: 2001\\nimdb_rating: 7.4\\nstudio: Dharma Productions\\nlanguage_id: 1\\nbudget: 390\\nrevenue: 1360\\nunit: Millions\\ncurrency: INR')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = CSVLoader(file_path=\"movies.csv\", source_column=\"title\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see from above that metadata has been updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'K.G.F: Chapter 2', 'row': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'K.G.F: Chapter 2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata.get('source') # `get` works for dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie_id: 106\\ntitle: Sholay\\nindustry: Bollywood\\nrelease_year: 1975\\nimdb_rating: 8.1\\nstudio: United Producers\\nlanguage_id: 1\\nbudget: Not Available\\nrevenue: Not Available\\nunit: Not Available\\ncurrency: Not Available'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[5].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we notice - we can see that `page_content` has csv header column names first and then a colon : and then the value in row as a converted version of row in string text form. So, this conversion attahces the context (colum name)  related to each cell for LLM to be able to interpret it.\n",
    "\n",
    "<span style = 'color: yellow'>May be we should see if we would have loded this csv data from a pdf how would it look? Would it still be able to give us the context : cell value type text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Table as PDF and compare it with CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'movies.pdf', 'page': 0}, page_content='movie_id title industry release_yearimdb_ratingstudio language_idbudget revenue unit\\n101 K.G.F: Chapter 2Bollywood 2022 8.4 Hombale Films 3 1 12.5 Billions\\n102 Doctor Strange in the Multiverse of MadnessHollywood 2022 7 Marvel Studios 5 200 954.8 Millions\\n103 Thor: The Dark WorldHollywood 2013 6.8 Marvel Studios 5 165 644.8 Millions\\n104 Thor: RagnarokHollywood 2017 7.9 Marvel Studios 5 180 854 Millions\\n105 Thor: Love and ThunderHollywood 2022 6.8 Marvel Studios 5 250 670 Millions\\n106 Sholay Bollywood 1975 8.1 United Producers 1 Not AvailableNot AvailableNot Available\\n107 Dilwale Dulhania Le JayengeBollywood 1995 8 Yash Raj Films 1 400 2000 Millions\\n108 3 Idiots Bollywood 2009 8.4 Vinod Chopra Films 1 550 4000 Millions\\n109 Kabhi Khushi Kabhie GhamBollywood 2001 7.4 Dharma Productions1 390 1360 Millions'),\n",
       " Document(metadata={'source': 'movies.pdf', 'page': 1}, page_content='currency\\nINR\\nUSD\\nUSD\\nUSD\\nUSD\\nNot Available\\nINR\\nINR\\nINR')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(file_path='movies.pdf')\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie_id title industry release_yearimdb_ratingstudio language_idbudget revenue unit\\n101 K.G.F: Chapter 2Bollywood 2022 8.4 Hombale Films 3 1 12.5 Billions\\n102 Doctor Strange in the Multiverse of MadnessHollywood 2022 7 Marvel Studios 5 200 954.8 Millions\\n103 Thor: The Dark WorldHollywood 2013 6.8 Marvel Studios 5 165 644.8 Millions\\n104 Thor: RagnarokHollywood 2017 7.9 Marvel Studios 5 180 854 Millions\\n105 Thor: Love and ThunderHollywood 2022 6.8 Marvel Studios 5 250 670 Millions\\n106 Sholay Bollywood 1975 8.1 United Producers 1 Not AvailableNot AvailableNot Available\\n107 Dilwale Dulhania Le JayengeBollywood 1995 8 Yash Raj Films 1 400 2000 Millions\\n108 3 Idiots Bollywood 2009 8.4 Vinod Chopra Films 1 550 4000 Millions\\n109 Kabhi Khushi Kabhie GhamBollywood 2001 7.4 Dharma Productions1 390 1360 Millions'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style = 'color: yellow'>We can see that the conversion of table in a pdf is not ideal. So, if we need to process a pdf containing tables, we should design a a carefully designed workflow because we want high quality conversion of pdf information into LLM readable and understandable text  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install required libraries\n",
    "# !pip3 install unstructured libmagic python-magic python-magic-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredURLLoader(\n",
    "    urls = [\n",
    "        \"https://www.moneycontrol.com/news/business/banks/hdfc-bank-re-appoints-sanmoy-chakrabarti-as-chief-risk-officer-11259771.html\",\n",
    "        \"https://www.moneycontrol.com/news/business/markets/market-corrects-post-rbi-ups-inflation-forecast-icrr-bet-on-these-top-10-rate-sensitive-stocks-ideas-11142611.html\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English\\n\\nHindi\\n\\nGujarati\\n\\nSpecials\\n\\nHello, Login\\n\\nHello, Login\\n\\nLog-inor Sign-Up\\n\\nMy Account\\n\\nMy Pro'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.moneycontrol.com/news/business/banks/hdfc-bank-re-appoints-sanmoy-chakrabarti-as-chief-risk-officer-11259771.html'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Splitters\n",
    "\n",
    "Why do we need text splitters in first place?\n",
    "\n",
    "LLM's have token limits. Hence we need to split the text which can be large into small chunks so that each chunk size is under the token limit. There are various text splitter classes in langchain that allows us to do this.\n",
    "\n",
    "**Later we will see that we also merge chunks. Why? - keep reading!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking some random text from wikipedia\n",
    "\n",
    "text = \"\"\"Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan. \n",
    "It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine. \n",
    "Set in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for humankind.\n",
    "\n",
    "Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007 and was originally set to be directed by Steven Spielberg. \n",
    "Kip Thorne, a Caltech theoretical physicist and 2017 Nobel laureate in Physics,[4] was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar. \n",
    "Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm. Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles. \n",
    "Interstellar uses extensive practical and miniature effects, and the company Double Negative created additional digital effects.\n",
    "\n",
    "Interstellar premiered in Los Angeles on October 26, 2014. In the United States, it was first released on film stock, expanding to venues using digital projectors. The film received generally positive reviews from critics and grossed over $677 million worldwide ($715 million after subsequent re-releases), making it the tenth-highest-grossing film of 2014. \n",
    "It has been praised by astronomers for its scientific accuracy and portrayal of theoretical astrophysics.[5][6][7] Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual approach of splitting text into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher N'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Say LLM token limit is 100, in that case we can do simple thing such as this\n",
    "\n",
    "text[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Well but we want complete words and want to do this for entire text, may be we can use Python's split funciton\n",
    "\n",
    "words = text.split(\" \")\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "\n",
    "s = \"\"\n",
    "for word in words:\n",
    "    s += word + \" \"\n",
    "    if len(s)>200:\n",
    "        chunks.append(s)\n",
    "        s = \"\"              # reset\n",
    "        \n",
    "chunks.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "202\n",
      "201\n",
      "203\n",
      "206\n",
      "201\n",
      "209\n",
      "212\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting data into chunks can be done in native python but it is a tidious process. Also if necessary, you may need to experiment with various delimiters in an iterative manner to ensure that each chunk does not exceed the token length limit of the respective LLM.**\n",
    "\n",
    "**Langchain provides a better way through text splitter classes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Text Splitter Classes from Langchain\n",
    "#### CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator='\\n',\n",
    "    chunk_size = 200, \n",
    "    chunk_overlap = 10  # we keep chunk overlap so that there is some context overlap between consecutive chunks and thus LLM knows which chunk to pick while answering us\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 210, which is longer than the specified 200\n",
      "Created a chunk of size 208, which is longer than the specified 200\n",
      "Created a chunk of size 358, which is longer than the specified 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = splitter.split_text(text)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "120\n",
      "210\n",
      "181\n",
      "197\n",
      "207\n",
      "128\n",
      "357\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all though we gave 200 as a chunk size since the split was based on \\n, it ended up creating chunks that are bigger than size 200.\n",
    "\n",
    "Another class from Langchain can be used to recursively split the text based on a list of separators. This class is **RecursiveTextSplitter**. Let's see how it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RecursiveTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can give a list of separators. The order/ sequence in the list matters.\n",
    "\n",
    "It will start with first separator and if criterias like chunk_size and overlap are met - it will move onto create next chunk but if in current chunk with current separator, the chunk_size is coming more than what you specified then, it will use the next separator from the list and divde the current chunk based on the newly selected separator. Let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators = [\"\\n\\n\", \"\\n\", \" \"],  # List of separators based on requirement (defaults to [\"\\n\\n\", \"\\n\", \" \"])\n",
    "    chunk_size = 200,  # size of each chunk created\n",
    "    chunk_overlap  = 0,  # size of  overlap between chunks in order to maintain the context\n",
    "    length_function = len  # Function to calculate size, currently we are using \"len\" which denotes length of string however you can pass any token counter)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "120\n",
      "199\n",
      "10\n",
      "181\n",
      "197\n",
      "198\n",
      "8\n",
      "128\n",
      "191\n",
      "165\n",
      "198\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "chunks = r_splitter.split_text(text)\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's understand how exactly it formed these chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439\n",
      "719\n",
      "612\n"
     ]
    }
   ],
   "source": [
    "first_splitter_chunks = text.split(\"\\n\\n\") # using the first separator\n",
    "for chunk in first_splitter_chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we consider the first chunk here of size 439, since it is larger than 200, it will use the second separator (\"\\n\") to further split it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "Len after first separator  439\n",
      "106\n",
      "121\n",
      "210\n",
      "--\n",
      "Len after first separator  719\n",
      "182\n",
      "198\n",
      "208\n",
      "128\n",
      "--\n",
      "Len after first separator  612\n",
      "358\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "first_splitter_chunks = text.split(\"\\n\\n\") # using the first separator\n",
    "for chunk in first_splitter_chunks:\n",
    "    print('--')\n",
    "    print('Len after first separator ', len(chunk))\n",
    "    if len(chunk)>200:\n",
    "        second_splitter_chunks = chunk.split(\"\\n\") # using the second separator\n",
    "        for chunk_ in second_splitter_chunks:\n",
    "            print(len(chunk_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even now we see a few chunk_ more than 200 in size. So, we go to thirs splitter which is space ->(\" \")\n",
    "\n",
    "When you split this using space, it will separate out each word and then it will merge those chunks such that their size is close to 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "Len after first separator  439\n",
      "106\n",
      "121\n",
      "210\n",
      " -> 195\n",
      " -> 14\n",
      "--\n",
      "Len after first separator  719\n",
      "182\n",
      "198\n",
      "208\n",
      " -> 198\n",
      " -> 8\n",
      "128\n",
      "--\n",
      "Len after first separator  612\n",
      "358\n",
      " -> 191\n",
      " -> 165\n",
      "253\n",
      " -> 198\n",
      " -> 54\n"
     ]
    }
   ],
   "source": [
    "first_splitter_chunks = text.split(\"\\n\\n\") # using the first separator\n",
    "for chunk in first_splitter_chunks:\n",
    "    print('--')\n",
    "    print('Len after first separator ', len(chunk))\n",
    "    if len(chunk)>200:\n",
    "        second_splitter_chunks = chunk.split(\"\\n\") # using the second separator\n",
    "        for chunk_ in second_splitter_chunks:\n",
    "            print(len(chunk_))\n",
    "            if len(chunk_)>200:\n",
    "                words_third_splitter = chunk_.split(\" \") # using the third separator SPACE - containing just words\n",
    "                final_chunks = []\n",
    "                s=\"\"\n",
    "                for word in words_third_splitter:\n",
    "                    \n",
    "                    if len(s) + len(word) + 1 > 199:\n",
    "                        final_chunks.append(s.strip())\n",
    "                        s = word + \" \"  # Start a new chunk with the current word\n",
    "                    else:\n",
    "                        s+= word+ \" \"\n",
    "\n",
    "                # Append the remaining text as the last chunk\n",
    "                if s.strip(): # means a non-empty string\n",
    "                    final_chunks.append(s.strip())  # Append the final chunk without trailing space\n",
    "\n",
    "                for _chunk_ in final_chunks:\n",
    "                    print(' ->' , len(_chunk_))\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it is very similar to the output of `RecursiveTextSplitter`\n",
    "\n",
    "Writing everything explicitly like hanling case of SPACE can be tedious to do everytime manually. That is why use langchain class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buteven after using langchain RecursiveTextSplitter, I(MG) think codebasics skipped the merging part where there are chunks of size 8 which is too small. So, may be for LLM size of 4096 we split them into chunks of max size 3800 allowing some bandwidth of mering. We should be using a good number of separators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the sequence of separators -> our chunks size can change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "196\n",
      "198\n",
      "199\n",
      "199\n",
      "198\n",
      "195\n",
      "199\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "# Let's see\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators = [\" \", \"\\n\\n\", \"\\n\"],  # List of separators based on requirement (defaults to [\"\\n\\n\", \"\\n\", \" \"])\n",
    "    chunk_size = 200,  # size of each chunk created\n",
    "    chunk_overlap  = 0,  # size of  overlap between chunks in order to maintain the context\n",
    "    length_function = len  # Function to calculate size, currently we are using \"len\" which denotes length of string however you can pass any token counter)\n",
    ")\n",
    "\n",
    "\n",
    "chunks = r_splitter.split_text(text)\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, it does!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "120\n",
      "199\n",
      "10\n",
      "181\n",
      "197\n",
      "198\n",
      "8\n",
      "128\n",
      "191\n",
      "165\n",
      "198\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "# Let's see\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators = [\"\\n\\n\", \"\\n\", \" \"],  # List of separators based on requirement (defaults to [\"\\n\\n\", \"\\n\", \" \"])\n",
    "    chunk_size = 200,  # size of each chunk created\n",
    "    chunk_overlap  = 0,  # size of  overlap between chunks in order to maintain the context\n",
    "    length_function = len  # Function to calculate size, currently we are using \"len\" which denotes length of string however you can pass any token counter)\n",
    ")\n",
    "\n",
    "\n",
    "chunks = r_splitter.split_text(text)\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Visual Effects, and received numerous other accolades.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted chunks:\n",
      "Chunk 1 (105 chars): Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan.\n",
      "Chunk 2 (120 chars): It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine.\n",
      "Chunk 3 (199 chars): Set in a dystopian future where humanity is embroiled in a catastrophic blight and famine, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for\n",
      "Chunk 4 (192 chars): humankind. Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007 and was originally set to be directed by Steven Spielberg.\n",
      "Chunk 5 (197 chars): Kip Thorne, a Caltech theoretical physicist and 2017 Nobel laureate in Physics,[4] was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar.\n",
      "Chunk 6 (198 chars): Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm. Principal photography began in late 2013 and took place in Alberta, Iceland, and Los\n",
      "Chunk 7 (137 chars): Angeles. Interstellar uses extensive practical and miniature effects, and the company Double Negative created additional digital effects.\n",
      "Chunk 8 (191 chars): Interstellar premiered in Los Angeles on October 26, 2014. In the United States, it was first released on film stock, expanding to venues using digital projectors. The film received generally\n",
      "Chunk 9 (165 chars): positive reviews from critics and grossed over $677 million worldwide ($715 million after subsequent re-releases), making it the tenth-highest-grossing film of 2014.\n",
      "Chunk 10 (198 chars): It has been praised by astronomers for its scientific accuracy and portrayal of theoretical astrophysics.[5][6][7] Interstellar was nominated for five awards at the 87th Academy Awards, winning Best\n",
      "Chunk 11 (54 chars): Visual Effects, and received numerous other accolades.\n"
     ]
    }
   ],
   "source": [
    "def merge_text_chunks(chunks, size_limit=256, min_size=50):\n",
    "    \"\"\"\n",
    "    Merge small text chunks with neighbors while respecting the size limit.\n",
    "\n",
    "    Parameters:\n",
    "        chunks (list[str]): List of text chunks.\n",
    "        size_limit (int): Maximum allowed size for a chunk.\n",
    "        min_size (int): Minimum size for a chunk.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: List of adjusted text chunks.\n",
    "    \"\"\"\n",
    "    merged_chunks = []\n",
    "    current_chunk = \"\"  # To accumulate chunks\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if len(chunk) < min_size and len(current_chunk) + len(chunk) <= size_limit:\n",
    "            # Merge small chunk into the current chunk\n",
    "            current_chunk += (\" \" if current_chunk else \"\") + chunk\n",
    "        elif len(current_chunk) + len(chunk) <= size_limit:\n",
    "            # Add chunk to the current chunk if within the size limit\n",
    "            current_chunk += (\" \" if current_chunk else \"\") + chunk\n",
    "        else:\n",
    "            # Save the current chunk if it exceeds the size limit\n",
    "            if current_chunk:\n",
    "                merged_chunks.append(current_chunk)\n",
    "            # Start a new chunk\n",
    "            current_chunk = chunk\n",
    "\n",
    "    # Add the last chunk if there's any leftover\n",
    "    if current_chunk:\n",
    "        merged_chunks.append(current_chunk)\n",
    "\n",
    "    return merged_chunks\n",
    "\n",
    "\n",
    "# Adjust chunks\n",
    "adjusted_chunks = merge_text_chunks(chunks, size_limit=200, min_size=50)\n",
    "print(\"Adjusted chunks:\")\n",
    "for idx, chunk in enumerate(adjusted_chunks, start=1):\n",
    "    print(f\"Chunk {idx} ({len(chunk)} chars): {chunk}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
