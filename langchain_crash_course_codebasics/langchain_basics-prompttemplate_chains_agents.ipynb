{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c26845d",
   "metadata": {},
   "source": [
    "# Langchain crash course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d241011",
   "metadata": {},
   "source": [
    "Langchain is a framework allowing us build applications with LLMs. When we use ChatGPT (which is not an LLM but an application), it makes call to OpenAI API which interacts with an LLM (like GPT-3.5/ GPT-4) to get the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ee7ef",
   "metadata": {},
   "source": [
    "environment = `rag_env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31c4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret_key import openapi_key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = openapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed0dc6a",
   "metadata": {},
   "source": [
    "## LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "295d2590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.13\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa352d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Deprecated \n",
    "# from langchain.llms import OpenAI # Other LLM providers: OpenAI, Cohere, Hugging Face \n",
    "# name = llm.predict('Who is Narendra Modi') # Deprecated: predict to invoke \n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9) # temperature controls creativity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f936e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = llm.invoke(\"I want to open a restaurant for Indian food. Suggest a fency name for this.\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49908065",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow\">default model is \"gpt-3.5-turbo-instruct\"</span>\n",
    "\n",
    "There is a list of openai models that we could use from list shown at https://api.python.langchain.com/en/latest/_modules/langchain_openai/llms/base.html#OpenAI\n",
    "\n",
    "The syntax would be \n",
    "`llm=OpenAI(model='gpt-4o', temperature=0.2)`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0782a2dd",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2582835",
   "metadata": {},
   "source": [
    "We don't want to keep writing the prompt for every query. In those case, we can use Prompt Templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a306b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to open a restaurant for Italian food. Suggest a fency name for this.\n",
      "\n",
      "\"Bellissimo Bistro\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "p = prompt_template_name.format(cuisine=\"Italian\")\n",
    "print(p)\n",
    "\n",
    "print(llm.invoke(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf620fb",
   "metadata": {},
   "source": [
    "Let's vary 2 (cusisine and place) variables instead of 1 (cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c65b0942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to open a restaurant for Italian food in India country. Suggest a fancy name and a city for this.\n",
      "\n",
      "\n",
      "\"Fresco Elegante\" in Mumbai, India.\n"
     ]
    }
   ],
   "source": [
    "prompt_template_name_place = PromptTemplate(\n",
    "    input_variables=['cuisine', 'place'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food in {place} country. Suggest a fancy name and a city for this.\"\n",
    ")\n",
    "\n",
    "p = prompt_template_name_place.format(cuisine=\"Italian\", place='India')\n",
    "print(p)\n",
    "\n",
    "print(llm.invoke(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af406b92",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff45eb8",
   "metadata": {},
   "source": [
    "What is we want to do multiple steps like decide a name of restaurant, a place for it and then create a menu for the dishes. Then, an easier way to handle is by using Chains. Here, ouptput of first step is input to second and output of second is input to third and so on. \n",
    "\n",
    "If we are using a `SimpleSequentialChain` then only the final output (last step's output) is returned and rest other intermediate outputs are not.\n",
    "\n",
    "So, if we need to get the intermediate outputs as well. We could use `SequentialChain`\n",
    "\n",
    "What other types of chain exists <span style=\"color:red\">???</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba65c213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.invoke(\"Mexican\")\n",
    "\n",
    "## Deprecated \n",
    "# chain.run -> chain.invoke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ce50c",
   "metadata": {},
   "source": [
    "<span style = \"color: yellow\"> If `verbose=True`, we will be able to see what's happening unde the hood and not just the final output.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5ccee75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI want to open a restaurant for Mexican food. Suggest a fency name for this.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Mexican', 'text': '\\n\\nCasa de Sabor (House of Flavor)'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, verbose=True)\n",
    "chain.invoke(\"Mexican\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2499d153",
   "metadata": {},
   "source": [
    "Suppose we want to create the name of restaurant and also create the menu on the basis of the name. So, let's create 2 chains - 1 for name and 1 for menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21098937",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
    ")\n",
    "\n",
    "name_chain =LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template=\"\"\"Suggest some menu items for {restaurant_name}\"\"\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94779d8",
   "metadata": {},
   "source": [
    "\n",
    "Now we can see that both these chains are not connected. Because if we want to create menu, we need name. Below I am providing the name myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ca3d985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'restaurant_name': 'Maharaja Spice',\n",
       " 'text': '\\n\\n1. Tandoori Chicken: Tender chicken marinated in a blend of spices and cooked in a clay oven.\\n\\n2. Butter Chicken: Boneless chicken cooked in a rich and creamy tomato-based sauce.\\n\\n3. Lamb Rogan Josh: A classic dish of tender lamb cooked in a spicy tomato and onion-based gravy.\\n\\n4. Vegetable Biryani: Fragrant basmati rice cooked with mixed vegetables, herbs, and spices.\\n\\n5. Palak Paneer: Soft cubes of paneer (Indian cottage cheese) cooked in a creamy spinach sauce.\\n\\n6. Dal Makhani: A popular lentil dish made with black lentils, kidney beans, and aromatic spices.\\n\\n7. Malai Kofta: Vegetable dumplings made with potatoes, carrots, and peas, served in a creamy cashew-based sauce.\\n\\n8. Aloo Gobi: A delicious combination of potatoes and cauliflower cooked with onions, tomatoes, and spices.\\n\\n9. Chicken Tikka Masala: Succulent pieces of chicken cooked in a flavorful tomato and onion-based sauce.\\n\\n10. Garlic Naan: Soft and fluffy Indian bread infused with garlic and cooked in a tandoor oven.\\n\\n11. Mango Lassi: A refreshing and creamy yogurt-based drink flavored with sweet mangoes.\\n\\n12.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_items_chain.invoke('Maharaja Spice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae141cc",
   "metadata": {},
   "source": [
    "Now, we don't want to pass the name by ourselves but get the name from 1st chain and pass that into 2nd chain. How can we do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a98d9f",
   "metadata": {},
   "source": [
    "#### Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9fd9a79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Indian', 'output': '\\n1. Spicy Chicken Tikka Masala\\n2. Lamb Vindaloo\\n3. Vegetable Samosas\\n4. Tandoori Shrimp Skewers\\n5. Aloo Gobi (spiced cauliflower and potatoes)\\n6. Chana Masala (spiced chickpea curry)\\n7. Butter Chicken\\n8. Beef Korma\\n9. Palak Paneer (spinach and cheese curry)\\n10. Dal Makhani (creamy lentil dish)\\n11. Tandoori Naan bread\\n12. Mango Lassi (a refreshing yogurt drink)\\n13. Spicy Chicken Biryani\\n14. Mixed Vegetable Pakoras\\n15. Lamb Rogan Josh (spicy lamb curry)\\n16. Achari Chicken (pickled spiced chicken)\\n17. Baingan Bharta (spiced eggplant dish)\\n18. Malai Kofta (vegetable and cheese dumplings in a creamy sauce)\\n19. Chicken Jalfrezi (spicy stir-fry with vegetables)\\n20. Gulab Jamun (sweet fried dough balls in syrup)'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain]) # sequence/order of the chains matter\n",
    "\n",
    "content = chain.invoke(\"Indian\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d9962",
   "metadata": {},
   "source": [
    "Here we can see that even if we got the menu as output (output of last chain), we didn't get the restaurant name (output of chain 1). To get intermediate outputs, use `SequentialChain`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386d05c",
   "metadata": {},
   "source": [
    "#### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49dc0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fency name for this.\"\n",
    ")\n",
    "\n",
    "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6610eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Indian',\n",
       " 'restaurant_name': '\\n\\n\"Spice Palace: A Taste of India\"'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_chain.invoke('Indian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "692b0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_name_place = PromptTemplate(\n",
    "    input_variables =['cuisine', 'place'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food inside {place}. Suggest a fancy name and a place for this.\"\n",
    ")\n",
    "\n",
    "name_place_chain =LLMChain(llm=llm, prompt=prompt_template_name_place, output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5acbef2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Indo-chinese',\n",
       " 'place': 'Mumbai',\n",
       " 'restaurant_name': '\\n\\nName: \"Spice Fusion Bistro\"\\n\\nLocation: Bandra West, Mumbai'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_place_chain.invoke({'cuisine': 'Indo-chinese', 'place': 'Mumbai'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9dea8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['restaurant_name'],\n",
    "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ec1be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name', \"menu_items\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4653c540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Indian',\n",
       " 'restaurant_name': '\\n\\n\"Spice Palace\"',\n",
       " 'menu_items': '\\n\\n1. Chicken Tikka Masala \\n2. Vegetable Samosas \\n3. Lamb Vindaloo \\n4. Chana Masala \\n5. Palak Paneer \\n6. Tandoori Chicken \\n7. Naan Bread \\n8. Mango Lassi \\n9. Aloo Gobi \\n10. Butter Chicken \\n11. Vegetable Biryani \\n12. Papadum \\n13. Dal Makhani \\n14. Chicken Korma \\n15. Gulab Jamun (dessert)'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"cuisine\": \"Indian\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069a75e",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceae63a",
   "metadata": {},
   "source": [
    "Agents  - will have access to external tools. Example: Expedia, mathematics function etc.\n",
    "\n",
    "Tools list: https://python.langchain.com/v0.1/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6ee719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure yoy have installed this package: pip install google-search-results\n",
    "from secret_key import serpapi_key\n",
    "os.environ['SERPAPI_API_KEY'] = serpapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b2c6b",
   "metadata": {},
   "source": [
    "#### serpapi and llm-math tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fec4212d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Calculator tool to solve this math problem.\n",
      "Action: Calculator\n",
      "Action Input: 2022 + 5 trillion\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 5000000002022\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This doesn't seem right, I should try a different approach.\n",
      "Action: Calculator\n",
      "Action Input: 2022 * 5 trillion\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 10110000000000000\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This answer seems more accurate, but I should double check with a different tool.\n",
      "Action: Search\n",
      "Action Input: \"GDP of US in 2022\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[\"The U.S. is a country of 50 states covering a vast swath of North America, with Alaska in the northwest and Hawaii extending the nation’s presence into the Pacific Ocean. Major Atlantic Coast cities are New York, a global finance and culture center, and capital Washington, DC. Midwestern metropolis Chicago is known for influential architecture and on the west coast, Los Angeles' Hollywood is famed for filmmaking. ― Google\", 'United States type: Country in North America.', 'United States entity_type: countries, locations, travel, competitions, military.', 'United States kgmid: /m/09c7w0.', 'Current-dollar GDP increased 9.2 percent, or $2.15 trillion, in 2022 to a level of $25.46 trillion, compared with an increase of 10.7 percent, ...', 'Current-dollar GDP increased 9.2 percent, or $2.15 trillion, in 2022 to a level of $25.46 trillion, compared with an increase of 10.7 percent, ...', 'Real GDP (constant, inflation adjusted) of the United States of America reached $18,924,600,000,000 in 2022. · GDP Growth Rate in 2022 was 2.06%, representing a ...', 'The Gross Domestic Product (GDP) in the United States was worth 27360.94 billion US dollars in 2023, according to official data from the World Bank.', 'In 2023, the US GDP increased from the previous year to about 27.36 trillion US dollars. This increase in GDP can be attributed to a continued rebound from the ...', 'Full Year GDP Growth in the United States increased to 2.90 percent in 2023 from 2.50 percent in 2022. This page includes a chart with historical data for ...', 'In 2023 the real gross domestic product (GDP) of the United States increased by 2.5 percent compared to 2022.', \"Overall, in the calendar year 2024, the United States' Nominal GDP at Current Prices totaled at $29.017 trillion, as compared to $25.744 trillion in 2022. The ...\", 'In 2022, GDP contracted at a 2.0% rate in the first quarter, revised down from the previously reported 1.6% pace. Consumer spending, now ...', 'Measured from the fourth quarter of 2022 to the fourth quarter of 2023, real GDP increased 3.1 percent during the period compared with an ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This information is helpful, but I still need to do some calculations to get the final answer.\n",
      "Action: Calculator\n",
      "Action Input: 25.46 trillion + 5 trillion\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 30460000000000.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This seems like a reasonable estimate for the GDP of the US in 2022 plus 5 trillion.\n",
      "Final Answer: The GDP of the US in 2022 plus 5 trillion is approximately $30.46 trillion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What was the GDP of US in 2022 plus 5 trillion?',\n",
       " 'output': 'The GDP of the US in 2022 plus 5 trillion is approximately $30.46 trillion.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "# from langchain.llms import OpenAI # Deprecated\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Let's test it out!\n",
    "agent.invoke(\"What was the GDP of US in 2022 plus 5 trillion?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a02710",
   "metadata": {},
   "source": [
    "####### Peculiar Agent Response Snapshot. See how it rectifies itself ########\n",
    "\n",
    "\n",
    "![alt text](peculiar_agent_response.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd3a12",
   "metadata": {},
   "source": [
    "#### Wikipedia and llm-math tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14d06ce6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's birthdate and age.\n",
      "Action: wikipedia\n",
      "Action Input: \"Elon Musk\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
      "Summary: Elon Reeve Musk  (; born June 28, 1971) is a businessman known for his key roles in the space company SpaceX and the automotive company Tesla, Inc. His other involvements include ownership of X Corp., the company that operates the social media platform X (formerly Twitter), and his role in the founding of the Boring Company, xAI, Neuralink, and OpenAI. Musk is the wealthiest individual in the world; as of December 2024, Forbes estimates his net worth to be US$432 billion.\n",
      "A member of the wealthy South African Musk family, Musk was born in Pretoria and briefly attended the University of Pretoria before immigrating to Canada at the age of 18, acquiring citizenship through his Canadian-born mother. Two years later, he matriculated at Queen's University at Kingston in Canada. Musk later transferred to the University of Pennsylvania and received bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University but never enrolled in classes, and with his brother Kimbal co-founded the online city guide software company Zip2. The startup was acquired by Compaq for $307 million in 1999. That same year, Musk co-founded X.com, a direct bank. X.com merged with Confinity in 2000 to form PayPal. In 2002, Musk acquired US citizenship, and that October eBay acquired PayPal for $1.5 billion. Using $100 million of the money he made from the sale of PayPal, Musk founded SpaceX, a spaceflight services company, in 2002. \n",
      "In 2004, Musk was an early investor in electric-vehicle manufacturer Tesla Motors, Inc. (later Tesla, Inc.), providing most of the initial financing and assuming the position of the company's chairman. He later became the product architect and, in 2008, the CEO. In 2006, Musk helped create SolarCity, a solar energy company that was acquired by Tesla in 2016 and became Tesla Energy. In 2013, he proposed a hyperloop high-speed vactrain transportation system. In 2015, he co-founded OpenAI, a nonprofit artificial intelligence research company. The following year Musk co-founded Neuralink, a neurotechnology company developing brain–computer interfaces, and The Boring Company, a tunnel construction company. In 2018 the U.S. Securities and Exchange Commission (SEC) sued Musk, alleging that he had falsely announced that he had secured funding for a private takeover of Tesla. To settle the case Musk stepped down as the chairman of Tesla and paid a $20 million fine. In 2022, he acquired Twitter for $44 billion, merged the company into the newly-created X Corp. and rebranded the service as X the following year. In March 2023, Musk founded xAI, an artificial-intelligence company.\n",
      "Musk's actions and expressed views have made him a polarizing figure. He has been criticized for making unscientific and misleading statements, including COVID-19 misinformation, promoting right-wing conspiracy theories, and endorsing an antisemitic trope; he has since apologized for the latter, but continued endorsing such statements. His ownership of Twitter has been controversial because of the layoffs of large numbers of employees, an increase in hate speech, misinformation and disinformation posts on the website, and changes to website features, including verification. \n",
      "By early 2024, Musk became active in American politics as a vocal and financial supporter of Donald Trump, becoming Trump's second-largest individual donor in October 2024. In November 2024, Trump announced that he had chosen Musk along with Vivek Ramaswamy to co-lead Trump's planned Department of Government Efficiency (DOGE) advisory board which will make recommendations on improving government efficiency through measures such as slashing \"excess regulations\" and cutting \"wasteful expenditures\".\n",
      "\n",
      "Page: Views of Elon Musk\n",
      "Summary: Elon Musk is the CEO or owner of multiple companies including Tesla, SpaceX, and X Corp, and has expressed many views on a wide variety of subjects, ranging from politics to science.\n",
      "Musk has often been de\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now that I have information about Elon Musk's birthdate and age, I can use a calculator to find his current age in 2023.\n",
      "Action: Calculator\n",
      "Action Input: 2023 - 1971\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 52\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Elon Musk is currently 52 years old in 2023.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'When was Elon musk born? What is his age right now in 2023?',\n",
       " 'output': 'Elon Musk is currently 52 years old in 2023.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install this package: pip install wikipedia\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Let's test it out!\n",
    "agent.invoke(\"When was Elon musk born? What is his age right now in 2023?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be7ee7",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d58096",
   "metadata": {},
   "source": [
    "Memory means remembering old conversation. But remembering all the old conversation is also not required. So, we could limit from practical pov where it becomes costly to store and retokenize & reprocess all the old queries in order to generate a response. So, in this section, we will see how we can limit it to say last 5 queries or last 2 queries and so on, depending upon our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2acab5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Mexican', 'text': '\\n\\n\"La Fiesta Mexicana\"'}\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "name = chain.invoke(\"Mexican\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bc200f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Indian', 'text': '\\n\\n\"Maharaja\\'s Palace\"'}\n"
     ]
    }
   ],
   "source": [
    "name = chain.invoke(\"Indian\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "229a6888",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a0f5fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad6feb42",
   "metadata": {},
   "source": [
    "<span style='color:yellow'> Nothing gets printed here because `chain.memory` is `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f492fb5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8947ad74",
   "metadata": {},
   "source": [
    "To add memory use `ConversationBufferMemory`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871492be",
   "metadata": {},
   "source": [
    "#### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53eea298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Mexican', 'history': '', 'text': '\\n\\n\"El Sabroso Cantina\"'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
    "name = chain.invoke(\"Mexican\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0de5d50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Arabic', 'history': 'Human: Mexican\\nAI: \\n\\n\"El Sabroso Cantina\"', 'text': '\\n\\n\"Al-Quds Oasis\"'}\n"
     ]
    }
   ],
   "source": [
    "name = chain.invoke(\"Arabic\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b569f600",
   "metadata": {},
   "source": [
    "As one can notice above, we start to see the `history`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cc88888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Mexican\n",
      "AI: \n",
      "\n",
      "\"El Sabroso Cantina\"\n",
      "Human: Arabic\n",
      "AI: \n",
      "\n",
      "\"Al-Quds Oasis\"\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da39b28",
   "metadata": {},
   "source": [
    "We can use these Q. Ans. pair later for finetuning/ creating a db/ monitoring after storing them\n",
    "\n",
    " <span style='color:yellow'> But the problem with current implmentation is that it will store all the interactions in memory in order to answer a new one. This is also true for the `ConversationChain` shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a88b5b",
   "metadata": {},
   "source": [
    "#### ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "687ddd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
    "print(convo.prompt.template) # default template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47ad5062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who won the first cricket world cup?',\n",
       " 'history': '',\n",
       " 'response': \" The first cricket world cup was won by West Indies in 1975. The final match was played between West Indies and Australia at Lord's Cricket Ground in London. West Indies won by 17 runs, with Clive Lloyd as their captain. Interestingly, the first match of the tournament was played between England and India at Lord's as well, with England winning by 202 runs.\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03c80b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How much is 5+5?',\n",
       " 'history': \"Human: Who won the first cricket world cup?\\nAI:  The first cricket world cup was won by West Indies in 1975. The final match was played between West Indies and Australia at Lord's Cricket Ground in London. West Indies won by 17 runs, with Clive Lloyd as their captain. Interestingly, the first match of the tournament was played between England and India at Lord's as well, with England winning by 202 runs.\",\n",
       " 'response': '  5+5 is equal to 10. This is a basic arithmetic equation and the answer is derived from the fact that 5+5 equals to 10.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07342f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who was the captain ofthe winning team?',\n",
       " 'history': \"Human: Who won the first cricket world cup?\\nAI:  The first cricket world cup was won by West Indies in 1975. The final match was played between West Indies and Australia at Lord's Cricket Ground in London. West Indies won by 17 runs, with Clive Lloyd as their captain. Interestingly, the first match of the tournament was played between England and India at Lord's as well, with England winning by 202 runs.\\nHuman: How much is 5+5?\\nAI:   5+5 is equal to 10. This is a basic arithmetic equation and the answer is derived from the fact that 5+5 equals to 10.\",\n",
       " 'response': ' The captain of the winning team for the first cricket world cup was Clive Lloyd of West Indies.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"Who was the captain ofthe winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e459d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Who won the first cricket world cup?\n",
      "AI:  The first cricket world cup was won by West Indies in 1975. The final match was played between West Indies and Australia at Lord's Cricket Ground in London. West Indies won by 17 runs, with Clive Lloyd as their captain. Interestingly, the first match of the tournament was played between England and India at Lord's as well, with England winning by 202 runs.\n",
      "Human: How much is 5+5?\n",
      "AI:   5+5 is equal to 10. This is a basic arithmetic equation and the answer is derived from the fact that 5+5 equals to 10.\n",
      "Human: Who was the captain ofthe winning team?\n",
      "AI:  The captain of the winning team for the first cricket world cup was Clive Lloyd of West Indies.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adbbc31",
   "metadata": {},
   "source": [
    "<span style='color:yellow'> Now using `ConversationBufferWindowMemory`, we can decide how many past conversations should be remembered and repassed as context to LLM to answer the new query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa3abd",
   "metadata": {},
   "source": [
    "#### ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "460eb33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first cricket world cup was won by the West Indies in 1975. It was held in England and the final match was played between the West Indies and Australia. The West Indies won by 17 runs.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1) # meaning remember only 1 last conversation and repass to LLM as context\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm=OpenAI(temperature=0.7),\n",
    "    memory=memory\n",
    ")\n",
    "convo.invoke(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395beaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 5+5 is equal to 10.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b24745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I do not have enough information to accurately answer that question. Could you provide me with more context?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.invoke(\"Who was the captain of the winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7089c760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who was the captain of the winning team?',\n",
       " 'history': 'Human: Who won the first cricket world cup?\\nAI:  The first cricket world cup was held in 1975 in England and was won by the West Indies team.\\nHuman: How much is 5+5?\\nAI:  5+5 is equal to 10.',\n",
       " 'response': ' The captain of the winning team was Clive Lloyd.'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(k=2) # meaning remember only 1 last conversation and repass to LLM as context\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm=OpenAI(temperature=0.7),\n",
    "    memory=memory\n",
    ")\n",
    "convo.invoke(\"Who won the first cricket world cup?\")\n",
    "convo.invoke(\"How much is 5+5?\")\n",
    "convo.invoke(\"Who was the captain of the winning team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f43bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d1408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e6820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
